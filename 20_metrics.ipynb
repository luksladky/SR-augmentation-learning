{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to srthesis.metrics,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "from nbdev import *\n",
    "%nbdev_default_export metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> Metrics used for evaluating model\n",
    "\n",
    "In addition to metrics traditionally used in image processing, PSNR and SSIM we'll used perception metrics, which are using activations from a pretrained classification AlexNet model, which is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export_internal\n",
    "import fastai\n",
    "import torch\n",
    "import os\n",
    "from fastai.metrics import psnr\n",
    "from ssim import ssim\n",
    "from fastai.vision import normalize_funcs, imagenet_stats\n",
    "\n",
    "os.sys.path.append('./PerceptualSimilarity')\n",
    "from PerceptualSimilarity import models as LPIPS_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export_internal\n",
    "norm, denorm = normalize_funcs(*imagenet_stats, do_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export_internal\n",
    "def denormalize(func):\n",
    "    \"\"\"Decorator dnormalizing image by pushing it to [0,1] range\"\"\"\n",
    "    def _denormalized(pred, targ):\n",
    "        pred = denorm(pred).clamp(min=0,max=1)\n",
    "        targ = denorm(targ).clamp(min=0,max=1)\n",
    "        return func(pred, targ)\n",
    "    _denormalized.__name__ = func.__name__\n",
    "    return _denormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional metrics\n",
    "Metrics traditionally used for image restoration benchmarking are PSNR and SSIM. They not always show the similarity as perceived by human observer, but are easily measurable and suitable for comparing different algorithms on a task with no geometric deformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak signal to noise ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "\n",
    "PSNR = denormalize(psnr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "SSIM = denormalize(ssim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual metrics \n",
    "\n",
    "Trained neural nets used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LPIPS (Learned Perceptual Image Patch Similarity) metric\n",
    "\n",
    "Paper [The Unreasonable Effectiveness of Deep Features as a Perceptual Metric](https://arxiv.org/abs/1801.03924). In principle it's similar to our Feature Loss, taking activations in this case from Alex Net and fine tuning according to a study with human participants on Amazon Mechanical Turk. There is adden another fully connected layer trying to predict the prefered image among two with different defformations. The activations from this layer are also used.\n",
    "\n",
    "This metric was used in recent image restoration competitions such as the recent NTIRE 2020 Challenge on Real-World Image Super-Resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/luslad/thesis/PerceptualSimilarity/models/weights/v0.1/alex.pth\n",
      "...[net-lin [alex]] initialized\n",
      "...Done\n"
     ]
    }
   ],
   "source": [
    "%nbdev_export\n",
    "\n",
    "_LPIPS_dist = LPIPS_models.PerceptualLoss(model='net-lin', net='alex')\n",
    "\n",
    "@denormalize\n",
    "def LPIPS(pred, targ): \n",
    "    result = _LPIPS_dist(pred, targ)\n",
    "    result = torch.mean(result).squeeze()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_utils.ipynb.\n",
      "Converted 0__template.ipynb.\n",
      "Converted 10_div2k.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_loss.ipynb.\n",
      "Converted augmentations.ipynb.\n",
      "Converted sr reference.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
